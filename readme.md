AI Email Support Assistant

An open, modular support ticket system with AI-powered classification and (soon) response automation.Built with FastAPI, PostgreSQL, and Hugging Face transformers.Designed for hands-on learning, extensibility, and real-world MLOps practice.

ğŸš€ Project Overview

This project is an end-to-end customer support platform that:

Receives and stores support tickets in a PostgreSQL database

Automatically classifies tickets by type (Billing, Technical, Account, Complaint, Feedback, Refund, Other) using zero-shot LLMs

(Next Milestone) Will generate automated response drafts using OpenAI or Hugging Face models

Provides a test/evaluation pipeline for measuring classification accuracy on synthetic and real-world tickets

ğŸ› ï¸ Tech Stack

FastAPI (async web API)

SQLAlchemy (async ORM)

PostgreSQL (Dockerized)

Alembic (migrations)

Pydantic v2 (validation)

Hugging Face Transformers (facebook/bart-large-mnli for zero-shot classification)

OpenAI API (optionally for ticket generation and LLMs)

httpie (for API testing)

Uvicorn (dev server)

Python 3.10+

ğŸ“‚ Code Structure

aiemailassistant/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                # FastAPI entrypoint
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â””â”€â”€ tickets.py         # API endpoints for ticket CRUD
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ models.py          # SQLAlchemy models
â”‚   â”‚   â””â”€â”€ database.py        # Session, engine setup
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ classifier.py      # Zero-shot classification logic
â”‚   â”œâ”€â”€ schemas.py             # Pydantic request/response schemas
â”‚   â””â”€â”€ ...
â”œâ”€â”€ alembic/                   # Migrations
â”œâ”€â”€ alembic.ini
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ load_synthetic_tickets.py  # Synthetic ticket generation script
â”œâ”€â”€ evaluate_classifier.py     # Ticket classification evaluation script
â”œâ”€â”€ synthetic_tickets.jsonl    # Synthetic ticket data (labeled)
â”œâ”€â”€ challenge_tickets.jsonl    # Ambiguous/realistic test tickets (labeled)
â”œâ”€â”€ .env.example               # Sample environment variables
â””â”€â”€ README.md

âš¡ Usage

Setup

Install dependencies

pip install -r requirements.txt

Configure environment variables

Copy `.env.example` to `.env` and fill in secrets/keys as needed. Do not commit `.env` (it is gitignored). If a key was previously committed, rotate it.

Set up the database

Start Postgres (locally or with Docker Compose)

Run Alembic migrations:

alembic upgrade head

Run the App

uvicorn app.main:app --reload --reload-dir ./app

API docs will be available at http://localhost:8000/docs.

Health checks

- Liveness/DB: `GET /health` â†’ `{ status: ok, db: up|down }`
- ML/GPU: `GET /health/ml` â†’ `{ gpu_available: bool, gpu_count: int }`

Test the Classifier

http POST http://localhost:8000/tickets/ subject="I need a refund" body="I was double charged."

The category will be assigned by the LLM.

Evaluate Performance

python evaluate_classifier.py

Prints classification metrics for both synthetic and challenge datasets.

ğŸ”¬ Model & ML Details

Classification: Uses Hugging Face facebook/bart-large-mnli zero-shot pipeline with custom prompt engineering.

Candidate labels:["Billing", "Technical", "Account", "Complaint", "Feedback", "Refund", "Other"]

Prompt:

Subject: ...
Body: ...
You are an expert support agent categorizing issues. Please classify this customer support message as one of: Billing, Technical, Account, Complaint, Feedback, Refund, Other. Only choose one label from this list.

GPU usage

- The classifier automatically uses GPU if `torch.cuda.is_available()` (device 0), else CPU.
- When running via Docker, ensure the container has GPU access (e.g., `docker run --gpus all ...` or configure Compose to request a GPU). Torch/Transformers will detect CUDA inside the container.

ğŸ§‘â€ğŸ’» Roadmap

 âœ…End-to-end async CRUD API with ticket storage

 âœ…Zero-shot classifier integration

 âœ…Evaluation notebook/script for real and synthetic tickets

 AI-powered response generation (OpenAI/Hugging Face, coming soon)

 Model monitoring, logging, and error handling improvements
 - Prometheus metrics for FastAPI and LLM latency
 - OpenTelemetry tracing via OTLP collector
 - Async DB-backed logging of app warnings/errors

 SetFit/few-shot/fine-tuned pipeline (future)

 CI/CD and Dockerization for deployment

ğŸ“š Learning Focus

This project is part of a personal LLM/AI learning track:

Building real AI apps from scratch (theory â†’ practice)

Exploring MLOps, deployment, and open-source best practices

Progressively moving from zero-shot â†’ few-shot â†’ fine-tuned models

ğŸ™Œ Contributions

Currently a solo project, but open to ideas, pull requests, or learning collabs!Feel free to fork, open issues, or suggest improvements.

License

MIT (see LICENSE)
